#this script is used to fit the full SP2 scattering signal of real particles 
#when run for non-incandescent reals this gives a set of data that can be used to set the fixed LEO fit parameters (width and centre position) over time


import sys
import os
import datetime
import pickle
import numpy as np
import matplotlib.pyplot as plt
from pprint import pprint
from scipy.optimize import curve_fit
from scipy import stats
from SP2_particle_record_UTC import ParticleRecord
from struct import *
import hk_new
import hk_new_no_ts_LEO
from scipy import linspace, polyval, polyfit, sqrt, stats
import math
import sqlite3
from datetime import datetime



#setup
data_dir = 'D:/2015/NETCARE_UBC_SP2/flight data/'  #'D:/2010/WHI_ECSP2/Binary/' #'D:/2009/WHI_ECSP2/Binary/'# 'D:/2010/WHI_ECSP2/Binary/'  #'D:/2012/WHI_UBCSP2/Binary/' 
instrument = 'UBCSP2' #'UBCSP2' #ECSP2
instrument_locn = 'POLAR6'
type_particle = 'nonincand' #nonincand, incand, Aquadag
start_analysis_at = datetime(2015,4,5)
end_analysis_at = 	datetime(2015,4,10)
num_records_to_analyse = 2000# 'all'
fit_function = 'Giddings' #Gauss or Giddings
show_full_fit = False
LEO_fit_percent = 0.05



#pararmeters used to reject invalid particle records based on scattering peak attributes
min_peakheight = 10
max_peakheight = 3700
min_peakpos = 40
max_peakpos = 160

record_size_bytes = 1498 #size of a single particle record in bytes(UBC_SP2 = 1498, EC_SP2 in 2009 and 2010 = 2458)


#setup database
conn = sqlite3.connect('C:/projects/dbs/SP2_data.db')
c = conn.cursor()

#sp2b_file TEXT, 			eg 20120405x001.sp2b
#file_index INT, 			
#instr TEXT,				eg UBCSP2, ECSP2
#instr_locn TEXT,			eg WHI, DMT, POLAR6
#particle_type TEXT,		eg PSL, nonincand, incand, Aquadag
#particle_dia FLOAT,				
#unix_ts_utc FLOAT,
#actual_scat_amp FLOAT,
#actual_peak_pos INT,
#FF_scat_amp FLOAT,
#FF_peak_pos INT,
#FF_gauss_width FLOAT,
#zeroX_to_peak FLOAT,
#LF_scat_amp FLOAT,
#incand_amp FLOAT,
#lag_time_fit_to_incand FLOAT,
#LF_baseline_pct_diff FLOAT,
#rBC_mass_fg FLOAT,
#coat_thickness_nm FLOAT,
#zero_crossing_posn FLOAT,
#coat_thickness_from_actual_scat_amp FLOAT,
#FF_fit_function TEXT,
#LF_fit_function TEXT,
#zeroX_to_LEO_limit FLOAT
#UNIQUE (sp2b_file, file_index, instr)
#)''')

#**********parameters dictionary**********
parameters = {
'acq_rate': 5000000,
#date and time
'timezone':-8,
#will be set by hk analysis
'avg_flow':120, #in vccm
#parameter to find bad flow durations
'flow_min' : 400,
'flow_max' : 1000,
'YAG_min' : 25,
'YAG_max' : 35,
'min_good_points' : 10,
#show plots?
'show_plot':True
}

def find_nearest(array,value):   #get index of value in array closest to value
	idx = (np.abs(array-value)).argmin()
	return idx
	
def gaussFullFit(parameters_dict):
	
	
	#*******HK ANALYSIS************ 

	#####comment this out if it's been run once
	
	####use for hk files with no timestamp (just time since midnight) (this should work for the EC polar flights in spring 2012,also for ECSP2 for WHI 20100610 to 20100026, UBCSP2 prior to 20120405)
	#avg_flow = hk_new_no_ts_LEO.find_bad_hk_durations_no_ts(parameters) 
	#parameters['avg_flow'] = avg_flow
	#bad_durations = []

	##use for hk files with timestamp (this is for the UBCSP2 after 20120405)
	#avg_flow = hk_new.find_bad_hk_durations(parameters)  #writes bad durations in UTC
	#parameters['avg_flow'] = avg_flow


	#*************LEO routine************
	
	
	for file in os.listdir('.'):
		
		if file.endswith('.sp2b'):
			
			print file
			
			path = parameters['directory'] + '/' + str(file)
			file_bytes = os.path.getsize(path) #size of entire file in bytes
			record_size = record_size_bytes  
			number_of_records = (file_bytes/record_size)-1
			if num_records_to_analyse == 'all':
				number_records_toshow =  number_of_records 
			else:
				number_records_toshow = num_records_to_analyse    
			
			##************This is the full-gauss prefit************
			
			f = open(file, 'rb')
			
			#grab the pickled bad_durations file generated by the HK analysis
			for hk_file in os.listdir('.'):
				if hk_file.endswith('.hkpckl'):
					hk_data = open(hk_file, 'r')
					bad_durations = pickle.load(hk_data)
					hk_data.close()
		
			record_index = 0      
			while record_index < number_records_toshow:
				
				##Import and parse binary
				record = f.read(record_size)
				try:
					particle_record = ParticleRecord(record, parameters['acq_rate'])
				except:
					print 'corrupt particle record'
					input("Press Enter to continue...")
					continue
				event_time = particle_record.timestamp
				
				###### FITTING AND ANALYSIS ########          
				number_bad_durations = len(bad_durations)
				
								
				#if there are any bad hk durations, note the beginning and end times of the first one
				if number_bad_durations:               
					bad_duration_start_time = bad_durations[0][0]#-parameters['timezone']  #needed timezone adjustemtn for 2010 data b/c the hk Bad durations lists were written in local time and I don't want to re-analyze them given the odd datestamping style
					bad_duration_end_time = bad_durations[0][1]#-parameters['timezone']
				
					#if the current event is after the end of the first bad duration in the list, pop that duration off, repeat if necessary until all bad durations before the event are gone
					while event_time >= bad_duration_end_time:
						if len(bad_durations): 
							bad_durations.pop(0)
							if len(bad_durations):
								bad_duration_start_time = bad_durations[0][0]#-parameters['timezone']
								bad_duration_end_time = bad_durations[0][1]#-parameters['timezone']
								continue
							else:
								break
				

				if not number_bad_durations or event_time < bad_duration_start_time:  

					#run the scatteringPeakInfo method to retrieve various peak attributes 
					particle_record.scatteringPeakInfo()
					actual_scat_signal = particle_record.getScatteringSignal()
					scattering_baseline = particle_record.scatteringBaseline
					actual_max_value = particle_record.scatteringMax
					actual_max_pos = particle_record.scatteringMaxPos
					
					#run the incandPeakInfo method to retrieve peak height
					particle_record.incandPeakInfo()
					incand_max = particle_record.incandMax
					

					#check to see if incandescence is negligible, scattering signal is over threshold, is in a reasonable position, and no double peaks
					if incand_max < 5. and actual_max_value > min_peakheight and actual_max_value < max_peakheight and actual_max_pos > min_peakpos and actual_max_pos < max_peakpos:
						
						#check zero crossing posn
						#note: zero-crossing calc will depend on the slope of the zero-crossing from the split detector
						zero_crossing_pt = particle_record.zeroCrossing()
						if zero_crossing_pt > 0: 
						
							#check for a double peak
							try:
								particle_record.isSingleParticle()
								
							except:
								print record_index
								print actual_max_value
								
							if particle_record.doublePeak==False:
							
								
							
								if fit_function == 'Giddings':
									particle_record.GiddingsFit()
									
								if fit_function == 'Gauss':
									particle_record.fullGaussFit()
								
								LEO_limit =  (actual_max_value)*LEO_fit_percent+scattering_baseline
								rising_signal = actual_scat_signal[0:actual_max_pos]
								LEO_limit_index = find_nearest(rising_signal,LEO_limit)+1 #plus 1 to avoid picking the index below
								zero_cross_to_LEO_limit = zero_crossing_pt - LEO_limit_index
																
								fit_peak_pos = particle_record.FF_peak_pos
								fit_width = particle_record.FF_width
								fit_scattering_amp = particle_record.FF_scattering_amp
								zero_cross_to_peak = (zero_crossing_pt - fit_peak_pos)
								
								#put particle into database or update record
								if fit_function == 'Gauss':
									c.execute('''INSERT or IGNORE into SP2_coating_analysis (sp2b_file, file_index, instr) VALUES (?,?,?)''', 
									(file, record_index,instrument))
									c.execute('''UPDATE SP2_coating_analysis SET 
									instr_locn=?, 
									particle_type=?,
									unix_ts_utc=?, 
									actual_scat_amp=?, 
									actual_peak_pos=?, 
									FF_fit_function=?,
									FF_scat_amp=?, 
									FF_peak_pos=?, 
									FF_gauss_width=?, 
									zeroX_to_peak=?,
									zeroX_to_LEO_limit=?,	
									FF_fit_function =?
									WHERE sp2b_file=? and file_index=? and instr=?''', 
									(instrument_locn,
									type_particle,
									event_time,
									actual_max_value,
									actual_max_pos,
									fit_function,
									fit_scattering_amp,
									fit_peak_pos,
									fit_width,
									zero_cross_to_peak,
									zero_cross_to_LEO_limit,
									fit_function,
									file, record_index,instrument))

								if fit_function == 'Giddings':
									c.execute('''INSERT or IGNORE into SP2_coating_analysis_Giddings_fit (sp2b_file, file_index, instr) VALUES (?,?,?)''', 
									(file, record_index,instrument))
									c.execute('''UPDATE SP2_coating_analysis_Giddings_fit SET 
									instr_locn=?, 
									particle_type=?,
									unix_ts_utc=?, 
									actual_scat_amp=?, 
									actual_peak_pos=?, 
									FF_fit_function=?,
									FF_scat_amp=?, 
									FF_peak_pos=?, 
									FF_gauss_width=?, 
									zeroX_to_peak=?,
									zeroX_to_LEO_limit=?,	
									FF_fit_function =?
									WHERE sp2b_file=? and file_index=? and instr=?''', 
									(instrument_locn,
									type_particle,
									event_time,
									actual_max_value,
									actual_max_pos,
									fit_function,
									fit_scattering_amp,
									fit_peak_pos,
									fit_width,
									zero_cross_to_peak,
									zero_cross_to_LEO_limit,
									fit_function,
									file, record_index,instrument))
									
								#plot particle fit if desired
								if show_full_fit == True:
									x_vals = particle_record.getAcqPoints()
									y_vals = particle_record.getScatteringSignal()
									fit_result = particle_record.FF_results
									#print datetime.utcfromtimestamp(event_time)
									print record_index, fit_width, zero_cross_to_peak			
									
									fig = plt.figure()
									ax1 = fig.add_subplot(111)
									ax1.plot(x_vals,y_vals,'o', markerfacecolor='None')   
									ax1.plot(x_vals,fit_result, 'red')
									#conn.commit()
									plt.show()

							

				record_index+=1   
					
			f.close()
		conn.commit()




os.chdir(data_dir)
for directory in os.listdir(data_dir):
	if os.path.isdir(directory) == True and directory.startswith('20'):
		parameters['folder']= directory
		folder_date = datetime.strptime(directory, '%Y%m%d')		
		if folder_date >= start_analysis_at and folder_date < end_analysis_at:
			parameters['directory']=os.path.abspath(directory)
			os.chdir(parameters['directory'])
			gaussFullFit(parameters)
			os.chdir(data_dir)
conn.close()	



	
